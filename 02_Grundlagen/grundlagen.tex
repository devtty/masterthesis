\chapter{Grundlagen}

\anno{bitte nicht mehr als 8 Seiten}

% Grundbegriffe 2 Seiten
\section{Grundbegriffe}
\subsection{WAF allgemein}
Um die Sicherheit einer Anwendung zu gewährleisten sind viele verschiedene Schritte notwendig, so sollten natürlich bereits in der Anwendung selbst Ein- und Ausgabemöglichkeiten, z.B. durch Validierung, Encoding, usw. überprüft und gegebenenfalls eingeschränkt werden. Dabei lässt sich nicht jeder mögliche Angriffsfall vorhersehen oder eine eigene Implementierung ist zu aufwendig und teuer, weil häufig nicht ausreichend personelle Ressourcen oder Bugdet vorhanden sind um eine Web Applikation auf alle möglichen Sicherheitslücken zu prüfen. Im Laufe des Betriebes einer Web Anwendungen können zudem neue Angriffsvarianten entstehen und zusätzlich ist gerade bei Web Applikationen der Zeitdruck zur Veröffentlichung einer solchen häufig sehr hoch.

An diesem Punkt kommen sogenannte Web Application Firewalls ins Spiel. Im Gegensatz zu regulären Firewalls haben Web Application Firewalls direkten Zugriff auf die HTTP-Anfragen (requests) und Antworten (responses) und können diese entsprechend bewerten und gegenbenenfalls blockieren oder gefährdende Inhalte filtern oder umschreiben.

%% 
\textcolor{bhtGray}{\ding{110} Definition\footnote{\url{https://owasp.org/www-community/Web_Application_Firewall} abgerufen am 30.05.2023}} A web application firewall is an application firewall for HTTP applications. It applies a set of rules to an HTTP conversation. Generally, these rules cover common attacks such as Cross-site Scripting (XSS) and SQL Injection. While proxies protect generally protect clients, WAFs protect servers. A WAF is deployed to protect a specific web application or set of web applications. A WAF can be considered a reverse proxy. WAFs may come in the form of an appliance, server plugin, or filter, and may be customized to an application to an application. The effort to perorm this customization can be significant and needs to be maintained as the application is modified.

%%
asd



\subsubsection{Anwendungsfälle}
%% Anwendungsfaelle WAF (gut beschrieben bei WAFEC2)
%% irgendwie Uebergang zu ML und WAF mit ML schaffen
%% Sammlung; payload,fuzzer,fingerprinting, bypassing

\subsection{Arten}

\subsubsection{Unterscheidung nach Position}
Grundsätzlich lassen sich solche Systeme nach ihrer Position in der Netzwerk- und Servertopologie unterscheiden. Es existieren einerseits Systeme die vor eine Anwendung geschaltet werden und Systeme die direkt in die Anwendung integriert werden. Die erste Gruppe lässt noch eine Verzweigung in weitere Unterarten, wie \emph{Reverse Proxy}, \emph{Appliance}, \emph{Plugins} für WebServer oder \emph{Passive Devices} (IDS), zu.


\subsubsection{Unterscheidung nach Abwehrmaßnahmen}

\paragraph{Regelbasierte Systeme}
Der Großteil bekannter WebApplicationFirewalls arbeitet jedoch \emph{regelbasiert}. In diesem Fall werden ein- und ausgehende Datenströme (Requests/Responses) unabhängig voneinander (zustandslos) betrachtet und einer Mustererkennung unterworfen. Häufig sind die Regeln anhand sogenannter \emph{Regular Expressions} definiert.

\paragraph{Logische Systeme}
Bei logikbasierten Abwehrmaßnahmen handelt es sich um Abwehrmaßnahmen die aufgrund von bekannten (logischen) Rückschlüssen eingeleitet werden. Einfachstes Beispiel wäre das temporäre Sperren der Loginseite bei dreimalig falschem Login. Bei Nutzung einer WAF die keine logikbasierten Auswertungen ermöglicht, müssten entsprechende Anwendungsfälle in der Anwendung selbst implementiert werden. (Oder im Fall der gerade beschriebenen Authentifizierungproblematik in einen externen Dienst ausgelagert werden.)

\subsection{Grundbegriffe allgemein}

\textbf{Bypassing:}

\textbf{Filter:}

\textbf{Fingerprinting:} Ähnlich der Abnahme und Identifizierung von Personen mit Hilfe eines individuellen Fingerabdrucks können auch Produkte wie Software anhand spezifischer Merkmale identifiziert werden. Beim \emph{Fingerprinting}

\textbf{Fuzzer:}

\textbf{Payload:}

\textbf{Reverse Proxy:}

\textbf{Regulärer Ausdruck:} Eine Zeichenkette zur Beschreibung einer Menge von Zeichenketten mit Hilfe einer vordefinierten Syntax. Ein regulärer Ausdruck kann bespielsweise genutzt werden um bestimmte Muster in einem Text zu erkennen oder einen Text mit einem Muster zu vergleichen.

\textbf{Request:} 

\textbf{Response:}

\section{Related Work} %umbenennen ca. 6

% Thema 1
\subsection{Evolution der Firewalls}

\subsubsection{Strikt nach Regeln}

Die praktisch einfachste Web Application Firewall wäre \emph{-beispielsweise-} eine einfache Regel innerhalb der Webserver-Konfiguration, die anhand eines bestimmten Merkmals den Datenverkehr entweder korrekt beantwortet oder \glqq\emph{abwehrt}\grqq. Wenn nicht explizit entnommen findet sich der folgende Eintrag in jeder Konfiguration des \emph{Apache httpd}-Servers und sorgt dafür dass der Zugriff auf jede Datei deren Dateiname mit \texttt{.ht} beginnt unterbunden wird:

\lstset{language=XML,
 	basicstyle=\ttfamily\color{black}\small,
 	keywordstyle=\bfseries\color{bhtBlue},
 	identifierstyle=\color{black}, 
 	commentstyle=\color{gray}\textsl
      }
%      \begin{figure}
%        \caption{Beispiel für einfache Regel}
%        \label{fig:httprule}
\begin{lstlisting}
  <Files ".ht*">
    Require all denied
  </Files>
\end{lstlisting}
%      \end{figure}

Mit steigender Komplexität der zu schützenden Anwendungen steigt auch der Bedarf an Regeln. Zu berücksichtigende Auswahlkriterien beschränken sich dann auch nicht nur auf den \glqq\emph{Dateinamen}\grqq. Attribute wie der Aufrufzeitpunkt, der Inhalt des Aufrufs, die Identität des Aufrufenden und viele andere Kriterien können zu entscheidenden Faktoren werden. Im Sinne der Entkopplung wurde diese Filterlogik häufig in entsprechende Module oder Plugins ausgelagert. Aufgrund des hohen Verbreitungsgrades des \emph{Apache httpd}-Servers wurde dessen \emph{modSecurity}-Modul zu einem der bekanntesten Vertreter einer Web Application Firewall. Dabei handelt es sich um eine frei verfügbare und als \emph{Open Source} entwickelte Softwarelösung, die eine eigene Sprache zum Erstellen der WAF-Regeln mit sich bringt. Der obige Aufruf zum Verhindern des Zugriffs auf Dateien die mit \texttt{.ht} beginnen lautet:

\lstset{language=bash,
 	basicstyle=\ttfamily\color{black}\small,
 	keywordstyle=\bfseries\color{bhtBlue},
 	identifierstyle=\color{black}, 
 	commentstyle=\color{gray}\textsl
      }
\begin{lstlisting}
  #SYNTAX: SecRule VARIABLES OPERATOR [ACTIONS]        
  SecRule REQUEST_URI ".ht*" "deny"
\end{lstlisting}
% end figure

Bei dieser Sicherheitsregel \verb=SecRule= wird die aufgerufene Adresse \verb=VARIABLES= auf Übereinstimmung mit einem regulären Ausdruck \verb=OPERATOR= geprüft und bei Übereinstimmung die Ausführung verweigert \verb=ACTIONS=.

\subsubsection{Allgemeine Regeln}
Mit der Zeit entwickelten sich immer mehr und immer komplexere Regeln. Regeln wurden auf spezielle Anwendungen, Anwendungsfälle oder Angriffsszenarien zugeschnitten und gesammelt. Es entstanden Sammlungen die unter Administratoren, Entwicklern und anderen IT-Spezialisten ausgetauscht wurden.
Im Oktober 2006 veröffentlichte das \emph{Open Web Application Security Project} erstmals eine allgemein verfügbare Sammlung von generischen Regeln für das modSecurity-Modul mit dem Ziel ein Art Grundschutz zur Absicherung von Webanwendungen anzubieten. Die als \emph{OWASP Core Rule Set} bekannte Sammlung wird seitdem stetig erweitert und weiter entwickelt. Wirft man heute einen Blick in die verfügbaren Regeldateien des Projekts \footnote{\url{https://github.com/coreruleset/coreruleset/tree/v4.0/dev/rules} abgerufen am 01.06.2023} findet man sowohl allgemeine Regeln mit Bezug auf die Angriffsmuster aus den OWASP Top10 \cite{owasp10}, als auch Regeln die sehr speziell auf bestimmte Anwendungen oder Sicherheitsvorfälle ausgelegt sind.

Obwohl die bereitgestellten Regeln des Core Rule Sets eine gewisse Basissicherheit bieten können, sind diese nur als Ausgangsbasis zur (produktiven) Absicherung von Anwendungen zu sehen. Erstens wird nicht jeder Fall berücksichtigt und zweitens erzeugen die Regeln unter Umständen auch Fehlmeldungen (Falsch-Positive).

\subsubsection{Von Regeln zur Logik}
Die Einträge in der Serverkonfiguration und die ersten Regeln im modSecurity-Modul erlaubten es die Anfragen an den Server entweder positiv oder negativ zu beantworten. Im Grunde könnte man die Funktionsweise zum damaligen Zeitpunkt mit einer \emph{Blacklist} bzw. \emph{Whitelist} für HTTP-Anfragen vergleichen. Einzelne Regeln entschieden über die Beantwortung einer Anfrage im positiven oder negativem Sinn. Mit der Weiterentwicklung des Moduls und der zweiten Version des Core Rule Sets wurden mit dem \emph{Scoring} und dem \emph{Paranoia-Level} zwei neue Funktionalitäten umgesetzt, die die Konfiguration für den Endanwender wesentlich vereinfachen sollten und auch einfache logische Entscheidungen ermöglichen sollten.

\textcolor{bhtGray}{\ding{110} Anmerkung} Natürlich erlauben \emph{Reguläre Ausdrücke} ebenfalls eine gewisse Logik und somit auch die darauf basierenden Regeln.

Beim \emph{Scoring} erfolgt die Auswertung der HTTP-Anfrage nicht in Form einer direkten Aktion, stattdessen wird als Ergebnis ein numerischer Wert festgelegt. Erst im Nachgang entscheidet die Firewall wie mit der Anfrage umzugehen ist. Das Scoring erlaubt es verschiedene Ergebnisse miteinander zu kombinieren und in Abhängigkeit voneinander auszuwerten. Technisch gesehen ist das HTTP-Protokoll zustandslos und bei einfachen Konfigurationen der WAF  wird jede einzelne Anfrage unabhängig von anderen Anfragen betrachtet. Der Scoring-Mechanismus erlaubt es in gewissem Maße auch zustandsbezogen zu agieren. \anno{Zu undeutlich? Blöd ausgedrückt?}

% weiter erklären!
% Idee: Ablaufdiagramme für Version 1(direkte Antwort) und 2 Scoring Mechanismus

\textcolor{bhtGray}{\ding{110} Beispiel} Eine Anfrage auf eine bestimmte Ressource bzw. URI soll abgelehnt werden wenn der Nutzer nicht eingeloggt ist. Dieser Fall wäre könnte mit drei einfachen Regeln abgebildet werden. Es wird für den Fall \emph{nicht eingeloggt} ein Punkt vergeben und für den Fall \emph{Aufruf der Ressource} ein Punkt vergeben. Die dritte Regel besagt dass alle Aufrufe deren Summe mehr als zwei Punkte in Summe überschreiten, abgelehnt werden.

\textcolor{bhtGray}{\ding{110} Beispiel} Angenommen ein unbekannter Internet-Nutzer versucht eine Anwendung durch nicht manipulierte Anfragen zu attackieren oder einen Brute-Force-Angriff auf eine sehr einfache Login-Maske und jeder misslungene Versuch wird erkannt bzw. bestätigt. In diesem Fall erzeugt die Anwendung mehrfach HTTP-Status-Codes abseits des üblichen Rückgabe-Wertes \verb=HTTP200 - OK=. Mit einem Scoring ist möglich diesen Nutzer bereits an den Versuchen zu hindern.
\begin{align}
  P = \frac{Scoring-Wert}{Anzahl_Anfragen gesamt}
\end{align}
\anno{Formel überprüfen?Weitermachen!}

In der ersten Version des CRS wurden alle der WAF bekannten Regeln auch aktiv umgesetzt und die Konfiguration der Firewall mußte in jedem Fall für die jeweilige Anwendung angepaßt werden. Nicht benötigte oder verkehrte (falsch-positiv liefernde) Regeln wurden der Konfiguration entnommen oder angepaßt. Die erstmalige Inbetriebnahme hatte damit einen erhöhten Arbeitsaufwand zur Folge. Die Einführung der Paranoia-Level erlaubte eine einfache und schnellere Konfiguration. Dazu wurden die Regeln nach Schweregraden kategorisiert und deren Ausführung in Abhängigkeit von vorkonfigurierten Werten gesteuert werden. Der Nutzer bekam die Möglichkeit eine sofort (bzw. mit sehr wenig Aufwand) einsetzbare Lösung zur erhalten, mit der seine Anwendung Schritt für Schritt sicherer werden konnte.

\begin{figure}[ht]
  %% \begin{center}
  \centering
  \includesvg[width=0.5\textwidth]{pl_onion_no_fonts}
  \caption{Übersicht Paranoia Level \cite{owaspcrs}}
  \label{fig.paranoia}
%%  \end{center}
\end{figure}


% Logik mit Zugriff auf die Anwendung -> WebCastellum?

\begin{neu}
  Kruegel Absatz über Anomalie-Detektoren? Hier einfügen!
\end{neu}

\subsubsection{Hybride Ansätze} %Nicht immer schwarz oder weiss
Ein Ergebnis muß aber nicht immer schwarz oder weiß sein.  Grundsätzlich besteht für Web Application Firewalls die Möglichkeit HTTP-Anfragen zu manipulieren bevor diese die eigentliche Anwendung erreichen. Gleiches gilt für die Antworten der Anwendung bevor diese an den Client ausgeliefert werden. Für den Apache httpd-Server existiert mit dem \emph{modRewrite}-Modul sogar eine Komponente einzig und allein für diesen Zweck. Ende 2010 erschien mit \glqq\emph{TokDoc: A Self-Healing Web Application Firewall}\grqq \cite{Krueger2010} ein Konferenzpaper mit dem Vorschlag, eingehende Anfragen in einzelne Bestandteile zu zerlegen, die einzelnen Bestandteile zu untersuchen und ggf. durch \emph{korrigierte} Äquivalente auszutauschen bevor diese an die zu schützende Anwendung weitergeleitet werden. Zusätzlich haben die Autoren des Papers die Bestandteile nach ihrem Ursprung in vier Kategorien eingeteilt:

\begin{table}[h]
  \centering
  \begin{tabular}{|l | p |}
    \hline
    Constants & In the simplest case the values of a token take the same value, for example the header field \verb=host= when monitoring a particular web host. \\
    Enumerations &  A second type of tokens carries data that takes on only a small set of values dependent either on the HTTP protocol itself or on the web application. An example of such token is the \verb=accept-language= header.\\
    Machine input & The third type of tokens comprises machine-generated data, such as session numbers, identifiers and cookies. \\
    Human input & The most complex token type is induced by human input, such as free-text fields, querystrings, comments and names. The entered data does not exhibit any semantical structure except for being generated by a natural language.  \\
    \hline
  \end{tabular}
  \caption{Kategorien nach \cite{Krueger2010}}
  \label{tab:tocdoc}
\end{table}

\begin{align}
  \overbrace{
    \underbrace{http}_\text{Konstante} \underbrace{www}_\text{maschine}\underbrace{seite}_\text{human}\underbrace{blog}_\text{maschine}\underbrace{search}_\text{maschine}\underbrace{=}_\text{Konstante}\underbrace{Hello}_\text{mensch}
  }^\text{GET-Request}
\end{align}

Die Auswertung der einzelnen Bestandteile erfolgte nicht mehr allein durch einen Abgleich mit Regeln bzw. regulären Ausdrücken sondern mittels sogenannten \emph{Anomalie-Detektoren}. 

% Krueger -> fehlerhafte Request werden automatisch korregiert und weiter geleitet
% Manaseer etc.

\subsubsection{Fortschritte in Richtung Intelligenz}

Collaborative Detection \cite{karakannas2014}

% kruegel gimenez appelt kozik testen mit ML Ansätzen

% Thema 2
\subsection{Thema 2 - ML}

%ansaetze und kombination?

% Thema 3 optional die andere seite
\subsection{hacking Wafs}


% Zusammenfassung (ca. 0,5 Seiten)
\section{Zusammenfassung}

% ggf. ditaa tabelle ueber den Zeitverlauf der verschiedenen Arbeiten nach Attack-Defend-Muster


November 2002 modSecurity 1st release
Oktober 2006 OWASP CRS
August 2009 CRS 2
2010 TokDoc
2014 Collaborative Detection
2016 CRS3.0.0 CRS Sampling Mode
2018 Centralized Manaseer